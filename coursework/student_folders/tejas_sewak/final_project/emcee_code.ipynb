{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048301f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code can only be run if xspec and models created specifically for xspec are present.  \n",
    "import time\n",
    "import xspec \n",
    "import numpy as np\n",
    "import emcee\n",
    "from multiprocessing import Pool\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# it needs model which is hard coded in the script below, so it can not be run.\n",
    "# will give an error something like â€” model relxillCp not available (no way out of this)\n",
    "# the data directory is about 400 Mb, so I am not attaching the data directory.\n",
    "xspec.Xset.restore(\"5660010101/xti/event_cl/fitted_files/analysis0_rexillCp_manual_chisqgti1.xcm\")\n",
    "initial_model = xspec.AllModels(1)\n",
    "\n",
    "par_val = [5,6,14,15,20,24,25,26] # thawed parameter number in the model. Example: 6th parameter is gamma of nthcomp.\n",
    "\n",
    "def log_Likelihood(params):\n",
    "    model = xspec.AllModels(1) # load the current model\n",
    "    # update each model parameter\n",
    "    for i in range(len(par_val)):\n",
    "        model(par_val[i]).values = params[i]\n",
    "    # calculate updated statistic and likelihood for those model parameters\n",
    "    cstat = xspec.Fit.statistic\n",
    "    log_likelihood = -0.5*cstat\n",
    "    return log_likelihood\n",
    "\n",
    "def log_Posterior(params):\n",
    "    # Defined for a uniform prior between parameter range.\n",
    "    # if any parameter is outside range, the prior value = 0, log(prior) = -inf, thus, log(Posterior) = -inf\n",
    "    for i in range(len(par_val)):\n",
    "        pval, pdelta, pmin, pbottom, ptop, pmax = initial_model(par_val[i]).values # the range is same throughout\n",
    "        # define a box-prior with the param range (in logarithm)\n",
    "        if params[i] < pmin or params[i] > pmax: \n",
    "            return -np.inf # log(0)\n",
    "    # if all parameters are within the range, the prior value = 1, log(prior) = 0, log(posterior) = log(likelihood) + 0\n",
    "    log_posterior = log_Likelihood(params)\n",
    "    return log_posterior\n",
    "\n",
    "# Run MCMC\n",
    "ndim = len(par_val)  # number of parameters in the model\n",
    "nwalkers = 256  # number of MCMC walkers\n",
    "burn = 500  # \"burn-in\" period to let chains stabilize\n",
    "nsteps = 10000  # number of MCMC steps to take **for each walker**\n",
    "\n",
    "# initialize theta \n",
    "\n",
    "best_fit = np.zeros(len(par_val))\n",
    "delta_values = np.zeros(len(par_val))\n",
    "for i in range(len(par_val)):\n",
    "    best_fit[i] = initial_model(par_val[i]).values[0]\n",
    "    delta_values[i] = initial_model(par_val[i]).values[1]\n",
    "\n",
    "starting_guesses = np.random.normal(loc=best_fit, scale=5*delta_values, size=(nwalkers, ndim))\n",
    "\n",
    "# the function call where all the work happens: \n",
    "start = time.time()\n",
    "with Pool() as pool:\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, log_Posterior,pool=pool)\n",
    "    start = time.time()    \n",
    "    sampler.run_mcmc(starting_guesses, nsteps)\n",
    "    end = time.time()\n",
    "    print(\"Time to run 100 iterations =\", end-start,\"s\")\n",
    "    from multiprocessing import cpu_count\n",
    "    ncpu = cpu_count()\n",
    "    print(\"{0} CPUs\".format(ncpu))\n",
    "\n",
    "# save the sampler\n",
    "print(\"Saving data\")\n",
    "filename = f\"sampler_w{nwalkers}_s{nsteps}.pkl\"\n",
    "with open(filename, \"wb\") as f:\n",
    "    pickle.dump(sampler, f)\n",
    "\n",
    "\n",
    "# sampler.chain is of shape (nwalkers, nsteps, ndim)\n",
    "# throw-out the burn-in points and reshape:\n",
    "emcee_trace  = sampler.chain[:, burn:, :].reshape(-1, ndim)\n",
    "np.save(\"emcee_trace_w{nwalkers}_s{nsteps}.npy\", emcee_trace)\n",
    "\n",
    "print(\"done\")\n",
    "\n",
    "print(sampler.chain.shape) #original chain structure\n",
    "print(emcee_trace.shape) #burned and flattened chain\n",
    "\n",
    "import corner\n",
    "import matplotlib.pyplot as plt\n",
    "import xspec\n",
    "\n",
    "# emcee_trace shape: (n_samples, len(par_val))\n",
    "nparams = len(par_val)\n",
    "assert emcee_trace.shape[1] == nparams, \"Mismatch in number of parameters\"\n",
    "\n",
    "param_labels = [initial_model(par).name for par in par_val]\n",
    "\n",
    "# Corner plot\n",
    "figure = corner.corner(\n",
    "    emcee_trace,\n",
    "    labels=param_labels,\n",
    "    quantiles=[0.16, 0.5, 0.84],\n",
    "    show_titles=True,\n",
    "    title_fmt=\".4f\",\n",
    "    title_kwargs={\"fontsize\": 12}\n",
    ")\n",
    "\n",
    "plt.savefig('emcee_p_w{nwalkers}_s{nsteps}.png',dpi=300)\n",
    "print(\"Congrats, job done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
